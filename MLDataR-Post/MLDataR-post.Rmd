---
title: "MLDataR - Real-world Datasets for Machine Learning Applications"
author: "Gary Hutson"
date: 2022-02-22
summary: "MLDataR is a package containing real-world datasets for machine learning applications."
output: html_document
---

*This is a guest post from Gary Hutson, lead of Machine Learning at Crisp Thinking, a company that provides AI solutions to moderate and detect offensive and abusive content online. His website is available at [https://hutsons-hacks.info/](https://hutsons-hacks.info/) and he can be reached through Twitter, [\@StatsGary](https://twitter.com/StatsGary).*

## MLDataR package motivation

I love all things Machine Learning. The [MLDataR](https://github.com/StatsGary/MLDataR) package was driven from the need to have example datasets from across the healthcare system for machine learning problems. I have been a machine learning practitioner for over 9 years; however, I still find it interesting to explore new examples and datasets related to supervised machine learning classification and regression.

Because the package contains clinical examples and examples from real hospital systems, it allows the potential machine learning engineer to practice on all things related to supervised machine learning. 

In spite of the package originally being aimed at healthcare, I have expanded it to new territories and domains.

## What does the package contain?

The package contains several datasets for modelling. This is just a start and I am working with the [NHS-R community](https://nhsrcommunity.com/) to build it out even further. It is a sort of a call to arms to equip the package with even more examples of excellent datasets that can be used for machine learning. 

**Diabetes disease prediction**  - This dataset contains key variables, gathered from hospital research and papers of the British Medical Journal, to identify the drivers behind diabetes disease. This dataset is useful for working with supervised classification machine learning problems or statistical problems. It uses past historic patient information to train and classify a model, with the aim to classify if a patient will have diabetes when they first present to the service.

**Diabetes early on set** - Gathered by Asif Laldin, the package contributor from Gloucestershire Clinical Commissioning Group, this dataset contains information on the time between a prediabetes diagnosis and the onset of diabetes.

**Failing care home prediction** - Using measures from the NHS incident reporting databases, this dataset contains data to classify if a care home will fail based on results from retrospective inspections.

**Heart disease prediction** - This dataset is intended for supervised machine learning classification problems on which patients are likely to present with heart disease. This uses independent variables, such as resting blood pressure, maximum heart rate, history of angina, and other metrics.

**Thyroid disease classification** - This one has a personal effect on me, as I am a sufferer of this disease. This drove me to source this dataset from the Garavan Institute, based on a collection of studies this institute did around thyroid disease. This contains 28 independent or predictor variables of patients with or without the disease. It is also covered in the [vignette supporting this package](https://cran.r-project.org/web/packages/MLDataR/vignettes/MLDataR.html) and the supporting YouTube tutorial using tidymodels with various ML techniques. 

**Counter Strike Global Offensive (CSGO)** - This dataset was kindly contributed by Asif Laldin, and is a detraction from the healthcare datasets in the package. I never intended the package to be purely healthcare ML datasets, and I have plans to include credit card fraud examples, tabular playground examples from Kaggle and many more, so watch this space...

## Run a tidymodels routine with heart disease dataset

Let's explore the heart disease dataset contained in MLDataR using a logistic regression model.

```{r, message = FALSE}
# install.packages("MLDataR")
library(MLDataR)
library(dplyr)
library(tidyr)
library(tidymodels)

glimpse(MLDataR::heartdisease)
```

A glimpse into the dataset gives us a quick overview of our dataset. We have 918 rows and 10 columns. We can see our outcome, heart disease, and our nine predictors.

There are a couple of things we want to clean up. Notice that our outcome variable `HeartDisease` loads as a double variable. We want to convert it into a factor variable for our machine learning model.

The variables `Sex`, `RestingECG`, and `Angina` are character variables. For creating models, it is better to have characters encoded as factors.

```{r}
hd <- heartdisease %>%
  mutate(across(where(is.character), as.factor),
         HeartDisease = as.factor(HeartDisease)) %>% 
  # Remove any noncomplete cases
  na.omit()

is.factor(hd$HeartDisease)
```

We use the recipes package to run the preprocessing steps for the model. These steps will make our model better.

With a logistic regression model, we want our predictors to be numeric. For factors like `RestingECG`, we convert them into "dummy variables" so that they are numeric. We can use `step_dummy()` to do this.

We want to remove any variables with zero variance from our model. To do this, we run `step_zv()`.

Finally, we want to normalize our predictors since they are on different scales from each other. The function `step_normalize()` helps us do this.

```{r}
hd_recipe <-
  recipes::recipe(HeartDisease ~ ., data = hd) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  recipes::step_zv(all_predictors()) %>% 
  recipes::step_normalize(all_predictors())

print(hd_recipe)
```

Now, we can create a `parsnip` model to build a workflow with the recipe we just created.

```{r}
lr_mod <- logistic_reg() %>%
  set_engine("glm") %>% 
  set_mode("classification")

lr_hd_wflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(hd_recipe)

lr_hd_wflow
```

We use `fit` to train the model:

```{r}
lr_hd_fit <- 
  lr_hd_wflow %>% 
  fit(data = hd)

lr_hd_fit
```

If we want to see the summary results of our model in a tidy way (i.e., a data frame with standard column names), we can use the `tidy()` function:

```{r}
tidy(lr_hd_fit)
```

Looking at the variables, we can see the statistically significant ones (p < 0.05): Cholesterol, FastingBS, MaxHR, HeartPeakReading, Sex, and Angina.

Let's convert the probabilities from the fitted GLM model into odds ratios. This will tell us, "for every change in 1 unit, what is the increase in odds of getting heart disease?"

We can visualize the results using the [OddsPlotty](https://cran.r-project.org/web/packages/OddsPlotty/index.html) package and the `fit` list object from the model.

```{r}
lr_hd_fit2 <- logistic_reg() %>%
  set_engine("glm") %>% 
  set_mode("classification") %>% 
  fit(HeartDisease ~ ., data = hd)

tidy_oddsplot <- OddsPlotty::odds_plot(lr_hd_fit$fit$fit$fit,
                                       title = "Heart Disease Odds Plot",
                                       point_col = "#6b95ff",
                                       h_line_color = "red")
tidy_oddsplot$odds_plot +
  theme(legend.position = "none")

```

# for Gary - attempt 2:

```{r}
tidy_oddsplot <- OddsPlotty::odds_plot(lr_hd_fit2$fit,
                                       title = "Heart Disease Odds Plot",
                                       point_col = "#6b95ff",
                                       h_line_color = "red")
tidy_oddsplot$odds_plot +
  theme(legend.position = "none")
```

## Can I contribute my own dataset that I have worked on?

The answer is you can and I would greatly encourage it. To boot, you will become a package contributor. I am looking for ML datasets from across a wide range of industries and organisations. If you have an idea, and are interested, please submit a pull request to the [GitHub repository](https://github.com/StatsGary/MLDataR) and add your dataset.

## Final Thoughts

I have really enjoyed putting this package together and I hope you can use it to:

**Learn tidymodels or caret.** I have put together a few tutorials on these in the past:

* Building a tidymodels classification model from scratch: https://www.youtube.com/watch?v=hxRx7ozLNKw&t=2583s
* Advanced modelling with caret for supervised machine learning: https://www.youtube.com/watch?v=rO40vvKXU-4&t=3085s
* Reticulate - R and Python a happy union: https://www.youtube.com/watch?v=8WE-EU5k97Q&t=235s
* Collapsing a caret confusion matrix with ConfusionTableR: https://youtu.be/9zcUlgLySZo

**Put your models into production:**

* Deploying a caret machine learning model as an API with Plumber: https://youtu.be/WMCkV_J5a0s
* Creating a microservice with Docker and serving as a restful API: https://youtu.be/JK6VLAKRjO4
